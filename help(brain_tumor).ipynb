{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+2wqq81KglnJgwDfP2ILQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutharimanikanta/Golab/blob/main/help(brain_tumor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x8eeZt47Xvc"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Function to read and preprocess images\n",
        "# def read_and_preprocess_images(test_directories, num_images_per_category=1, image_size=(80, 80)):\n",
        "#     images = []  # List to store images for each category\n",
        "#     for category_list in test_directories:\n",
        "#         category_images = []  # List to store images for a single category\n",
        "#         for category_path in category_list:\n",
        "#             for filename in os.listdir(category_path)[:num_images_per_category]:\n",
        "#                 img_path = os.path.join(category_path, filename)\n",
        "#                 img = cv2.imread(img_path)\n",
        "#                 img = cv2.resize(img, image_size)\n",
        "#                 category_images.append(img)  # Append preprocessed image\n",
        "#         images.append(category_images)  # Append images for the category\n",
        "#     return images\n",
        "\n",
        "# # Test directories (list of lists)\n",
        "# test_directories = [\n",
        "#     [\"/path/to/your/test_dataset_folder/glioma_tumor\"],\n",
        "#     [\"/path/to/your/test_dataset_folder/meningioma_tumor\"],\n",
        "#     [\"/path/to/your/test_dataset_folder/no_tumor\"],\n",
        "#     [\"/path/to/your/test_dataset_folder/pituitary_tumor\"]\n",
        "# ]\n",
        "\n",
        "# # Load sample images from each category within the test directories\n",
        "# sample_images = read_and_preprocess_images(test_directories)\n",
        "\n",
        "# # Function to display sample images\n",
        "# def display_sample_images(sample_images):\n",
        "#     num_categories = len(sample_images)\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     for i, category_images in enumerate(sample_images, start=1):\n",
        "#         num_images = len(category_images)\n",
        "#         for j, img in enumerate(category_images, start=1):\n",
        "#             plt.subplot(num_categories, num_images, (i-1)*num_images + j)\n",
        "#             plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "#             plt.title(f\"Category {i}, Image {j}\")\n",
        "#             plt.axis('off')\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # Display sample images from each category\n",
        "# display_sample_images(sample_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model, optimizers\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# class Autoencoder(Model):\n",
        "#     def __init__(self, latent_dim, shape):\n",
        "#         super(Autoencoder, self).__init__()  # Call super().__init__()\n",
        "#         self.latent_dim = latent_dim\n",
        "#         self.shape = shape\n",
        "#         self.encoder = tf.keras.Sequential([\n",
        "#             layers.InputLayer(input_shape=shape),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2))  # Adjusted to match the input shape\n",
        "#         ])\n",
        "#         self.decoder = tf.keras.Sequential([\n",
        "#             layers.Conv2DTranspose(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(shape[-1], (3, 3), activation='sigmoid', padding='same')\n",
        "#         ])\n",
        "#         self.build((None,) + shape)  # Explicitly build the model\n",
        "\n",
        "#     def call(self, x):\n",
        "#         encoded = tf.cast(x, tf.float32)  # Cast input data to float32\n",
        "#         encoded = self.encoder(encoded)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return decoded\n",
        "\n",
        "# # Assuming shape is properly defined as (80, 80, 3)\n",
        "# shape = (80, 80, 3)\n",
        "# latent_dim = 4\n",
        "# autoencoder = Autoencoder(latent_dim, shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "N24R1R7B7cV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model\n",
        "\n",
        "# class Autoencoder(Model):\n",
        "#     def __init__(self, latent_dim, shape):\n",
        "#         super(Autoencoder, self).__init__()\n",
        "#         self.latent_dim = latent_dim\n",
        "#         self.shape = shape\n",
        "#         self.encoder = tf.keras.Sequential([\n",
        "#             layers.InputLayer(input_shape=shape),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2))  # Adjusted to match the input shape\n",
        "#         ])\n",
        "#         self.decoder = tf.keras.Sequential([\n",
        "#             layers.Conv2DTranspose(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(shape[-1], (3, 3), activation='sigmoid', padding='same')\n",
        "#         ])\n",
        "#         self.build((None,) + shape)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         encoded = self.encoder(x)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return decoded\n",
        "\n",
        "\n",
        "# # Assuming shape is properly defined as (80, 80, 3)\n",
        "# # Assuming shape is properly defined as (80, 80, 3)\n",
        "# X_train_shape = (80,80,3)#X_train.shape[1:]   # Update this line with the correct input shape\n",
        "# latent_dim = 4\n",
        "# autoencoder = Autoencoder(latent_dim, X_train_shape)\n"
      ],
      "metadata": {
        "id": "3pko5BQ47e9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Assuming X_train and X_test are properly defined\n",
        "# X_train_resized = tf.image.resize(X_train, (80, 80))\n",
        "# X_test_resized = tf.image.resize(X_test, (80, 80))\n",
        "\n",
        "# # Normalize the pixel values to the range [0, 1]\n",
        "# X_train_resized = X_train_resized / 255.0\n",
        "# X_test_resized = X_test_resized / 255.0\n"
      ],
      "metadata": {
        "id": "ScfIi2pd7ius"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# class Autoencoder(Model):\n",
        "#     def __init__(self, latent_dim, shape):\n",
        "#         super(Autoencoder, self).__init__()  # Call super().__init__()\n",
        "#         self.latent_dim = latent_dim\n",
        "#         self.shape = shape\n",
        "#         self.encoder = tf.keras.Sequential([\n",
        "#             layers.InputLayer(input_shape=shape),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2))  # Adjusted to match the input shape\n",
        "#         ])\n",
        "#         self.decoder = tf.keras.Sequential([\n",
        "#             layers.Conv2DTranspose(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(shape[-1], (3, 3), activation='sigmoid', padding='same')\n",
        "#         ])\n",
        "#         self.build((None,) + shape)  # Explicitly build the model\n",
        "\n",
        "#     def call(self, x):\n",
        "#         encoded = tf.cast(x, tf.float32)  # Cast input data to float32\n",
        "#         encoded = self.encoder(encoded)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return decoded\n",
        "\n",
        "# # Define shape and latent dimension\n",
        "# shape = (80, 80, 3)\n",
        "# latent_dim = 4\n",
        "\n",
        "# # Instantiate autoencoder\n",
        "# autoencoder = Autoencoder(latent_dim, shape)\n",
        "\n",
        "# # Compile autoencoder\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YjhSTqTQ7nN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoencoder.compile(loss='mse',\n",
        "#                     optimizer=Adam(learning_rate=0.1),\n",
        "#                     metrics=['accuracy'])\n",
        "\n",
        "# # Train autoencoder\n",
        "# history = autoencoder.fit(X_train, X_train,\n",
        "#                           epochs=5,\n",
        "#                           shuffle=True,\n",
        "#                           validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "id": "LkyKsgeH7oHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = autoencoder.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_pred_classes[1]"
      ],
      "metadata": {
        "id": "K-Bvk0qt-cE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lr_range_test(X_train, X_test, shape, latent_dim, start_lr, end_lr, batch_size, epochs):\n",
        "    autoencoder = Autoencoder(latent_dim, shape)\n",
        "\n",
        "    # Define a learning rate scheduler callback\n",
        "    def lr_scheduler(epoch, lr):\n",
        "        return start_lr * (end_lr / start_lr) ** (epoch / epochs)\n",
        "\n",
        "    # Compile the model with an initial learning rate\n",
        "    autoencoder.compile(loss='mse', optimizer=Adam(learning_rate=start_lr), metrics=['accuracy'])\n",
        "\n",
        "    # Define the LearningRateScheduler callback\n",
        "    lr_callback = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "    # Train the model with LR range test\n",
        "    history = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, shuffle=True,\n",
        "                               validation_data=(X_test, X_test), callbacks=[lr_callback], verbose=0)\n",
        "\n",
        "    return history.history['loss'], history.history['accuracy'], autoencoder\n",
        "\n",
        "# Define LR range test parameters\n",
        "start_lr = 1e-7\n",
        "end_lr = 10\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Perform LR range test\n",
        "losses, accuracies, autoencoder = lr_range_test(X_train, X_test, shape, latent_dim, start_lr, end_lr, batch_size, epochs)\n",
        "\n",
        "# Plot the learning rate vs. loss curve\n",
        "learning_rates = start_lr * (end_lr / start_lr) ** (np.arange(epochs) / epochs)\n",
        "plt.plot(learning_rates, losses)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Rate vs. Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot the learning rate vs. accuracy curve\n",
        "plt.plot(learning_rates, accuracies)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Rate vs. Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NzxvzGk3A_BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
        "\n",
        "# Get reconstructed outputs for X_train and X_test\n",
        "reconstructed_train = autoencoder.predict(X_train)\n",
        "reconstructed_test = autoencoder.predict(X_test)\n",
        "\n",
        "# Assuming y_train and y_test contain the true labels for X_train and X_test respectively\n",
        "# Compute confusion matrix, F1 score, and recall for train and test sets\n",
        "y_train_pred = np.argmax(reconstructed_train, axis=3).flatten()\n",
        "y_train_true = np.argmax(X_train, axis=3).flatten()\n",
        "train_conf_matrix = confusion_matrix(y_train_true, y_train_pred)\n",
        "train_f1_score = f1_score(y_train_true, y_train_pred, average='weighted')\n",
        "train_recall = recall_score(y_train_true, y_train_pred, average='weighted')\n",
        "\n",
        "y_test_pred = np.argmax(reconstructed_test, axis=3).flatten()\n",
        "y_test_true = np.argmax(X_test, axis=3).flatten()\n",
        "test_conf_matrix = confusion_matrix(y_test_true, y_test_pred)\n",
        "test_f1_score = f1_score(y_test_true, y_test_pred, average='weighted')\n",
        "test_recall = recall_score(y_test_true, y_test_pred, average='weighted')\n",
        "\n",
        "print(\"Train Confusion Matrix:\")\n",
        "print(train_conf_matrix)\n",
        "print(\"Train F1 Score:\", train_f1_score)\n",
        "print(\"Train Recall:\", train_recall)\n",
        "\n",
        "print(\"\\nTest Confusion Matrix:\")\n",
        "print(test_conf_matrix)\n",
        "print(\"Test F1 Score:\", test_f1_score)\n",
        "print(\"Test Recall:\", test_recall)\n"
      ],
      "metadata": {
        "id": "bcZU6y0gBDWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# def cropAndAugmentation():\n",
        "#     # Augmentation Code\n",
        "#     IMG_SIZE = 80\n",
        "#     ADD_PIXELS = 5  # Adjust as needed\n",
        "#     dim = (IMG_SIZE, IMG_SIZE)\n",
        "#     cwd = os.getcwd()\n",
        "#     directory = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
        "#     desired_folder = \"Brain-Tumor-Classification-DataSet/Training/\"\n",
        "\n",
        "#     # Create copies of the original dataset with different modifications\n",
        "#     datasets = []\n",
        "#     for i in range(3):\n",
        "#         datasets.append([])\n",
        "\n",
        "#     for input_folder in directory:\n",
        "#         input_folder_path = os.path.join(cwd, desired_folder + input_folder)\n",
        "#         if not os.path.exists(input_folder_path):\n",
        "#             raise FileNotFoundError(f\"Input folder {input_folder_path} does not exist.\")\n",
        "\n",
        "#         for img in os.listdir(input_folder_path):\n",
        "#             image_path = os.path.join(input_folder_path, img)\n",
        "#             image = cv2.imread(image_path)\n",
        "\n",
        "#             # Resize images for the three datasets\n",
        "#             resized_image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "#             rotated_image = cv2.rotate(resized_image, cv2.ROTATE_90_CLOCKWISE)\n",
        "#             flipped_image = cv2.flip(resized_image, 1)  # Flip along the vertical direction\n",
        "\n",
        "#             # Append resized images to datasets\n",
        "#             datasets[0].append(resized_image)\n",
        "#             datasets[1].append(rotated_image)\n",
        "#             datasets[2].append(flipped_image)\n",
        "\n",
        "#     # Concatenate the three datasets into one\n",
        "#     concatenated_dataset = np.concatenate(datasets, axis=0)\n",
        "\n",
        "#     # Split the dataset into training and testing sets\n",
        "#     X_train, X_test = train_test_split(concatenated_dataset, test_size=0.1, random_state=42)\n",
        "#     # Create an iterator for training data with augmentation\n",
        "#     train_iterator = demo_datagen.flow(X_train, batch_size=32, shuffle=True)\n",
        "\n",
        "#     # Store training and testing data\n",
        "#     data_dir = \"./data\"\n",
        "#     train_dir = os.path.join(data_dir, \"train\")\n",
        "#     test_dir = os.path.join(data_dir, \"test\")\n",
        "\n",
        "#     os.makedirs(train_dir, exist_ok=True)\n",
        "#     os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "#     # Store training images\n",
        "#     for idx, img_batch in enumerate(train_iterator):\n",
        "#         for img in img_batch:\n",
        "#             category_folder = directory[idx % len(directory)]\n",
        "#             img_path = os.path.join(train_dir, category_folder, f\"image_{idx}.jpg\")\n",
        "#             os.makedirs(os.path.join(train_dir, category_folder), exist_ok=True)\n",
        "#             cv2.imwrite(img_path, img)\n",
        "#             idx += 1  # Increment index for the next image\n",
        "\n",
        "#         if idx >= len(X_train):  # Stop when all original training images are processed\n",
        "#             break\n",
        "\n",
        "#     # Store testing images\n",
        "#     for idx, img in enumerate(X_test):\n",
        "#         img_path = os.path.join(test_dir, f\"image_{idx}.jpg\")\n",
        "#         cv2.imwrite(img_path, img)\n",
        "#     # Count total number of images\n",
        "#     total_images = len(X_train) + len(X_test)\n",
        "#     print(\"Total number of images:\", total_images)\n",
        "#     print(\"Number of training images:\", len(X_train))\n",
        "#     print(\"Number of testing images:\", len(X_test))\n",
        "\n",
        "#     # print after crop\n",
        "#   # '''  # Comment this section during execution\n",
        "#     if flag2==0:\n",
        "#       plt.figure(figsize=(15,6))\n",
        "#       plt.imshow(new_image)\n",
        "#       plt.xticks([])\n",
        "#       plt.yticks([])\n",
        "#       plt.title('Step2: After Crop')\n",
        "#       plt.show()\n",
        "#      #plot_crops()\n",
        "#       flag2=1\n",
        "#   #  '''  #Display crops----------------------------------------------------------\n",
        "#       #def plot_crops()\n",
        "#       # '''  # Comment this section during execution\n",
        "#       plt.figure(figsize=(15,6))\n",
        "#       plt.subplot(141)\n",
        "#       plt.imshow(image)\n",
        "#       plt.xticks([])\n",
        "#       plt.yticks([])\n",
        "#       plt.title('Step 1. Get the original image')\n",
        "#       plt.subplot(142)\n",
        "#       plt.imshow(img_cnt)\n",
        "#       plt.xticks([])\n",
        "#       plt.yticks([])\n",
        "#       plt.title('Step 2. Find the biggest contour')\n",
        "#       plt.subplot(143)\n",
        "#       plt.imshow(img_pnt)\n",
        "#       plt.xticks([])\n",
        "#       plt.yticks([])\n",
        "#       plt.title('Step 3. Find the extreme points')\n",
        "#       plt.subplot(144)\n",
        "#       plt.imshow(new_image)\n",
        "#       plt.xticks([])\n",
        "#       plt.yticks([])\n",
        "#       plt.title('Step 4. Crop the image')\n",
        "#       plt.show()\n",
        "# # Execute the function\n",
        "# cropAndAugmentation()\n"
      ],
      "metadata": {
        "id": "W8FNUgfxHpbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to preprocess input images before sending them to the model\n",
        "def preprocess_input_images(input_images):\n",
        "    processed_images = []\n",
        "    for img in input_images:\n",
        "        # Resize the image to the desired input shape (e.g., 80x80)\n",
        "        img = cv2.resize(img, (80, 80))\n",
        "        # Normalize pixel values to the range [0, 1]\n",
        "        img = img / 255.0\n",
        "        processed_images.append(img)\n",
        "    return np.array(processed_images)\n",
        "\n",
        "# Function to predict output images using the autoencoder model\n",
        "def predict_output_images(input_images, autoencoder_model):\n",
        "    output_images = []\n",
        "    for img in input_images:\n",
        "        img = np.expand_dims(img, axis=0)  # Expand dimensions to match model input shape\n",
        "        reconstructed_img = autoencoder_model.predict(img)  # Predict output image\n",
        "        output_images.append(reconstructed_img[0])  # Append to the list\n",
        "    return output_images\n",
        "\n",
        "# List of input directories and corresponding output directories\n",
        "input_directories = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
        "output_directories = [\"glioma_tumor_o\", \"meningioma_tumor_o\", \"no_tumor_o\", \"pituitary_tumor_o\"]\n",
        "\n",
        "# Path to the main directory containing subdirectories\n",
        "main_directory = \"/content/data/train\"\n",
        "\n",
        "# Create a new main folder for the output directories\n",
        "output_main_directory = \"/content/output_data1\"\n",
        "os.makedirs(output_main_directory, exist_ok=True)\n",
        "\n",
        "# Iterate over each input directory\n",
        "for input_dir, output_dir in zip(input_directories, output_directories):\n",
        "    input_path = os.path.join(main_directory, input_dir)\n",
        "    output_path = os.path.join(output_main_directory, output_dir)\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Iterate over each image in the input directory\n",
        "    for img_name in os.listdir(input_path):\n",
        "        img_path = os.path.join(input_path, img_name)\n",
        "        # Read the input image\n",
        "        input_img = cv2.imread(img_path)\n",
        "        # Preprocess the input image\n",
        "        preprocessed_img = preprocess_input_images([input_img])[0]\n",
        "        # Predict the output image using the autoencoder model\n",
        "        output_img = predict_output_images([preprocessed_img], autoencoder)[0]\n",
        "        # Save the output image\n",
        "        output_img_path = os.path.join(output_path, img_name)\n",
        "        cv2.imwrite(output_img_path, output_img)\n"
      ],
      "metadata": {
        "id": "PtwUbQ8Ciav5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "from sklearn.utils import shuffle\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "#Custom Neural Network ClassÂ¶\n",
        "\n",
        "class BrainTumorModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1,256,kernel_size=3),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(256,32,kernel_size=2)\n",
        "        )\n",
        "        self.linear1 = nn.Linear(62,128)\n",
        "        self.linear2 = nn.Linear(128,64)\n",
        "        self.flat = nn.Flatten(1)\n",
        "        self.linear3 = nn.Linear(126976,2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.linear3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = BrainTumorModel()\n",
        "model.to(device)\n",
        "\n",
        "#CNN\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "loss_list = []\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for n in range(len(dataset)//batch_size):\n",
        "\n",
        "        data,target = dataset[n*batch_size:(n+1)*batch_size]\n",
        "\n",
        "        ypred = model.forward(data.float())\n",
        "        loss = loss_fn(ypred,target)\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_list.append(total_loss/batch_size)\n",
        "    if epoch%10 == 0:\n",
        "        print(f'Epochs: {epoch} Loss: {total_loss/n}')\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "plt.plot(list(range(epochs)),loss_list)\n",
        "plt.title(\"Loss v/s Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "mapping = {0:'no',1:'yes'}\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for i in range(20):\n",
        "    data,target = dataset[i]\n",
        "    pred = model.forward(data.float())\n",
        "    pred = torch.argmax(pred,dim=1)\n",
        "    plt.subplot(4,5,i+1)\n",
        "    plt.imshow(data[0][0].cpu())\n",
        "    plt.title(f'Actual: {mapping[target.cpu().detach().item()]} Predicted: {mapping[pred.cpu().detach().item()]}')\n",
        "plt.show()\n",
        "\n",
        "#Autoencoder\n",
        "\n",
        "dataset_autoencoder = BrainMRIDataset(\"../input/shiva_mri\",autoencoder=True,height=28,width=28)\n",
        "\n",
        "class BrainTumorAutoencodes(nn.Module):\n",
        "\n",
        "    def __init__(self,dim):\n",
        "\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(dim*dim,542)\n",
        "        self.lin2 = nn.Linear(542,345)\n",
        "        self.lin3 = nn.Linear(345,128)\n",
        "        self.lin4 = nn.Linear(128,64)\n",
        "        self.lin5 = nn.Linear(64,32)\n",
        "        self.lin6 = nn.Linear(32,64)\n",
        "        self.lin7 = nn.Linear(64,128)\n",
        "        self.lin8 = nn.Linear(128,345)\n",
        "        self.lin9 = nn.Linear(345,542)\n",
        "        self.lin10 = nn.Linear(542,dim*dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        x = F.relu(self.lin3(x))\n",
        "        x = F.relu(self.lin4(x))\n",
        "        x = self.lin5(x)\n",
        "        x = F.relu(self.lin6(x))\n",
        "        x = F.relu(self.lin7(x))\n",
        "        x = self.lin8(x)\n",
        "        x = F.relu(self.lin9(x))\n",
        "        x = F.relu(self.lin10(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "autoencoder = BrainTumorAutoencodes(28)\n",
        "autoencoder.to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters())\n",
        "\n",
        "from IPython.display import clear_output\n",
        "epochs = 500\n",
        "batch_size = 32\n",
        "loss_list = []\n",
        "for epoch in range(epochs):\n",
        "    clear_output(True)\n",
        "    total_loss = 0\n",
        "    for n in range(len(dataset_autoencoder)//batch_size):\n",
        "\n",
        "        data,target = dataset_autoencoder[n*batch_size:(n+1)*batch_size]\n",
        "\n",
        "        ypred = autoencoder.forward(data.float())\n",
        "        loss = loss_fn(ypred,data.float())\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_list.append(total_loss/batch_size)\n",
        "\n",
        "    figure = plt.figure(figsize=(20,20))\n",
        "    for i in range(20):\n",
        "        plt.subplot(4,5,i+1)\n",
        "        image = ypred[i].cpu().detach().numpy()# plot the sample\n",
        "        image = image.reshape(28,28)\n",
        "        fig = plt.figure\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f'Epochs: {epoch} Loss: {total_loss/n}')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IcogusM-HcFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}