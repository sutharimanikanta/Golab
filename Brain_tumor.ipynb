{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutharimanikanta/Golab/blob/main/Brain_tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2vOj7xxvH5N",
        "outputId": "43df627c-55b4-4928-c7cf-56ba05500551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Brain-Tumor-Classification-DataSet'...\n",
            "remote: Enumerating objects: 3039, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 3039 (delta 0), reused 0 (delta 0), pack-reused 3035\u001b[K\n",
            "Receiving objects: 100% (3039/3039), 79.25 MiB | 30.71 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SartajBhuvaji/Brain-Tumor-Classification-DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzA0UkVvvdSH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import keras.optimizers\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxoWJeIkvev_",
        "outputId": "c2e9e60f-a354-486e-8e83-c89b8f7b8b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piwBaKi_vgwD"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcr5NfyWvvdu"
      },
      "outputs": [],
      "source": [
        "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
        "                          write_graph=True, write_images=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5VOyKxovxvi"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "demo_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.05,\n",
        "    brightness_range=[0.1, 1.5],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccrzwdrWvzKw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define categories\n",
        "categories = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
        "\n",
        "# Define paths for training and testing data\n",
        "train_dir = \"./data/train\"\n",
        "test_dir = \"./data/test\"\n",
        "\n",
        "# Function to create directories\n",
        "def make_directories(base_dir):\n",
        "    for category in categories:\n",
        "        os.makedirs(os.path.join(base_dir, category), exist_ok=True)\n",
        "\n",
        "# Create directories for training data\n",
        "make_directories(train_dir)\n",
        "\n",
        "# Create directory for testing data\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Hicf3nv1H6",
        "outputId": "4e969527-bc9a-4064-d351-0742359257d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 8610\n",
            "Number of training images: 7749\n",
            "Number of testing images: 861\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "def cropAndAugmentation():\n",
        "    # Augmentation Code\n",
        "    IMG_SIZE = 80\n",
        "    ADD_PIXELS = 5  # Adjust as needed\n",
        "    dim = (IMG_SIZE, IMG_SIZE)\n",
        "    cwd = os.getcwd()\n",
        "    directory = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
        "    desired_folder = \"Brain-Tumor-Classification-DataSet/Training/\"\n",
        "\n",
        "    # Create copies of the original dataset with different modifications\n",
        "    datasets = []\n",
        "    for i in range(3):\n",
        "        datasets.append([])\n",
        "\n",
        "    for input_folder in directory:\n",
        "        input_folder_path = os.path.join(cwd, desired_folder + input_folder)\n",
        "        if not os.path.exists(input_folder_path):\n",
        "            raise FileNotFoundError(f\"Input folder {input_folder_path} does not exist.\")\n",
        "\n",
        "        for img in os.listdir(input_folder_path):\n",
        "            image_path = os.path.join(input_folder_path, img)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Resize images for the three datasets\n",
        "            resized_image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "            rotated_image = cv2.rotate(resized_image, cv2.ROTATE_90_CLOCKWISE)\n",
        "            flipped_image = cv2.flip(resized_image, 1)  # Flip along the vertical direction\n",
        "\n",
        "            # Append resized images to datasets\n",
        "            datasets[0].append(resized_image)\n",
        "            datasets[1].append(rotated_image)\n",
        "            datasets[2].append(flipped_image)\n",
        "\n",
        "    # Concatenate the three datasets into one\n",
        "    concatenated_dataset = np.concatenate(datasets, axis=0)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test = train_test_split(concatenated_dataset, test_size=0.1, random_state=42)\n",
        "    # Create an iterator for training data with augmentation\n",
        "    train_iterator = demo_datagen.flow(X_train, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Store training and testing data\n",
        "    data_dir = \"./data\"\n",
        "    train_dir = os.path.join(data_dir, \"train\")\n",
        "    test_dir = os.path.join(data_dir, \"test\")\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Store training images\n",
        "    for idx, img_batch in enumerate(train_iterator):\n",
        "        for img in img_batch:\n",
        "            category_folder = directory[idx % len(directory)]\n",
        "            img_path = os.path.join(train_dir, category_folder, f\"image_{idx}.jpg\")\n",
        "            os.makedirs(os.path.join(train_dir, category_folder), exist_ok=True)\n",
        "            cv2.imwrite(img_path, img)\n",
        "            idx += 1  # Increment index for the next image\n",
        "\n",
        "        if idx >= len(X_train):  # Stop when all original training images are processed\n",
        "            break\n",
        "\n",
        "    # Store testing images\n",
        "    for idx, img in enumerate(X_test):\n",
        "        img_path = os.path.join(test_dir, f\"image_{idx}.jpg\")\n",
        "        cv2.imwrite(img_path, img)\n",
        "    # Count total number of images\n",
        "    total_images = len(X_train) + len(X_test)\n",
        "    print(\"Total number of images:\", total_images)\n",
        "    print(\"Number of training images:\", len(X_train))\n",
        "    print(\"Number of testing images:\", len(X_test))\n",
        "\n",
        "# Execute the function\n",
        "cropAndAugmentation()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moTck_jnwWFe"
      },
      "outputs": [],
      "source": [
        "TEST_DIR = '/content/data/test' # test data folder\n",
        "TRAIN_DIR = '/content/data/train' # train data folder\n",
        "CATEGORIES =[\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
        "from tqdm import tqdm\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za6q-jLV3YYi"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP4Ggc8IwbGu",
        "outputId": "b69f1b06-c053-4efd-dc87-6752293f046a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1938/1938 [00:00<00:00, 10614.19it/s]\n",
            "100%|██████████| 1937/1937 [00:00<00:00, 10402.01it/s]\n",
            "100%|██████████| 1937/1937 [00:00<00:00, 10263.21it/s]\n",
            "100%|██████████| 1937/1937 [00:00<00:00, 11246.29it/s]\n"
          ]
        }
      ],
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(TRAIN_DIR, category)  # create path\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            # iterate over each image per category\n",
        "            img_path = os.path.join(path, img)\n",
        "            img_array = cv2.imread(img_path, cv2.IMREAD_COLOR)  # convert to array\n",
        "            if img_array is not None:\n",
        "                # Resize the image to the desired size (e.g., 80x80)\n",
        "                img_array = cv2.resize(img_array, (80, 80))\n",
        "                training_data.append(img_array)  # Use only input images\n",
        "            else:\n",
        "                print(f\"Failed to read image: {img_path}\")\n",
        "\n",
        "    random.shuffle(training_data)\n",
        "    print(\"Total number of images in training data:\", len(training_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izl-r7E4wetv",
        "outputId": "5a28bc8a-f7ef-4650-d1f7-1ff8dfaf7131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7749\n",
            "train data\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert the list of tuples into a single numpy array\n",
        "training_data_array = np.array(training_data, dtype=object)\n",
        "\n",
        "# Save the training data array\n",
        "np.save('train_data.npy', training_data_array)\n",
        "print(len(training_data_array))\n",
        "print(\"train data\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoFqTPV4HueJ",
        "outputId": "d0e16dfb-636b-4023-9ce8-d8b016d0c5ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "training_data_array[5][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSCY3rif4U2-"
      },
      "outputs": [],
      "source": [
        "# X_train = np.array([i[0] for i in training_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "# Y_train = [i[1] for i in training_data]# features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftoKQFGqwhXw",
        "outputId": "ac92c201-0af1-4aa2-d7b7-efdf77f1202e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 861/861 [00:00<00:00, 7833.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in testing data: 861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "testing_data = []\n",
        "\n",
        "def create_testing_data():\n",
        "    for img in tqdm(os.listdir(TEST_DIR)):\n",
        "        img_path = os.path.join(TEST_DIR, img)\n",
        "        if os.path.isfile(img_path):\n",
        "            img_array = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if img_array is not None:\n",
        "                # Resize the image to the desired size (e.g., 80x80)\n",
        "                img_array = cv2.resize(img_array, (80, 80))\n",
        "                testing_data.append(img_array)\n",
        "            else:\n",
        "                print(f\"Failed to read image: {img_path}\")\n",
        "        else:\n",
        "            print(f\"Not a file: {img_path}\")\n",
        "\n",
        "    random.shuffle(testing_data)\n",
        "    print(\"Total number of images in testing data:\", len(testing_data))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O5pK1Cwwj6R",
        "outputId": "d07cd430-28f6-420e-9e87-f9970ce46803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "861\n",
            "test data\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert the list of tuples into a single numpy array\n",
        "testing_data_array = np.array(testing_data, dtype=object)\n",
        "\n",
        "# Save the training data array\n",
        "np.save('test_data.npy', training_data_array)\n",
        "print(len(testing_data))\n",
        "print(\"test data\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfYM_1DC4why"
      },
      "outputs": [],
      "source": [
        "# Convert to NumPy array\n",
        "X_train = np.array([i[0] for i in training_data])\n",
        "Y_train = np.array([i[1] for i in training_data])\n",
        "# Convert to NumPy array\n",
        "X_test = np.array([i[0] for i in testing_data])\n",
        "Y_test = np.array([i[1] for i in testing_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-v8XDiOUjAp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6hHdaRZwtR_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, Dropout\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo3nr8t8OQap"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model, optimizers\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# class Autoencoder(Model):\n",
        "#     def __init__(self, latent_dim, shape):\n",
        "#         super(Autoencoder, self).__init__()  # Call super().__init__()\n",
        "#         self.latent_dim = latent_dim\n",
        "#         self.shape = shape\n",
        "#         self.encoder = tf.keras.Sequential([\n",
        "#             layers.InputLayer(input_shape=shape),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2))  # Adjusted to match the input shape\n",
        "#         ])\n",
        "#         self.decoder = tf.keras.Sequential([\n",
        "#             layers.Conv2DTranspose(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(shape[-1], (3, 3), activation='sigmoid', padding='same')\n",
        "#         ])\n",
        "#         self.build((None,) + shape)  # Explicitly build the model\n",
        "\n",
        "#     def call(self, x):\n",
        "#         encoded = tf.cast(x, tf.float32)  # Cast input data to float32\n",
        "#         encoded = self.encoder(encoded)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return decoded\n",
        "\n",
        "# # Assuming shape is properly defined as (80, 80, 3)\n",
        "# shape = (80, 80, 3)\n",
        "# latent_dim = 4\n",
        "# autoencoder = Autoencoder(latent_dim, shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF7c4rcViLgN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "class Autoencoder(Model):\n",
        "    def __init__(self, latent_dim, shape):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.shape = shape\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.InputLayer(input_shape=shape),\n",
        "            layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.1),\n",
        "            layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.1),\n",
        "            layers.Conv2D(32, (2, 2), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.UpSampling2D((2, 2))  # Adjusted to match the input shape\n",
        "        ])\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            layers.Conv2DTranspose(32, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "            layers.Dropout(0.1),\n",
        "            layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "            layers.Dropout(0.1),\n",
        "            layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.1),\n",
        "            layers.Conv2DTranspose(shape[-1], (3, 3), activation='sigmoid', padding='same')\n",
        "        ])\n",
        "        self.build((None,) + shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "\n",
        "# Assuming shape is properly defined as (80, 80, 3)\n",
        "# Assuming shape is properly defined as (80, 80, 3)\n",
        "shape = (80, 80, 3)  # Update this line with the correct input shape\n",
        "latent_dim = 4\n",
        "autoencoder = Autoencoder(latent_dim, shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOfdcpDfRGDA"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Assuming X_train and X_test are properly defined\n",
        "# X_train_resized = tf.image.resize(X_train, (80, 80))\n",
        "# X_test_resized = tf.image.resize(X_test, (80, 80))\n",
        "\n",
        "# # Normalize the pixel values to the range [0, 1]\n",
        "# X_train_resized = X_train_resized / 255.0\n",
        "# X_test_resized = X_test_resized / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8LkbhiyxLTM"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(loss='mse',\n",
        "                          optimizer=Adam(learning_rate=0.1),\n",
        "                          metrics=['accuracy'],\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "2QiaFI3WiRz-",
        "outputId": "b311ef9d-a470-46aa-dc63-269910ae7783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file1n8plimu.py\", line 10, in tf__call\n        encoded = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'autoencoder_2' (type Autoencoder).\n    \n    in user code:\n    \n        File \"<ipython-input-20-b259ae384018>\", line 49, in call  *\n            encoded = self.encoder(x)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 80, 80, 3), found shape=(None, 80, 3)\n    \n    \n    Call arguments received by layer 'autoencoder_2' (type Autoencoder):\n      • x=tf.Tensor(shape=(None, 80, 3), dtype=uint8)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-0ee94b2eb3c7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history=autoencoder.fit(X_train, X_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 validation_data=(X_test, X_test))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file1n8plimu.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file1n8plimu.py\", line 10, in tf__call\n        encoded = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'autoencoder_2' (type Autoencoder).\n    \n    in user code:\n    \n        File \"<ipython-input-20-b259ae384018>\", line 49, in call  *\n            encoded = self.encoder(x)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 80, 80, 3), found shape=(None, 80, 3)\n    \n    \n    Call arguments received by layer 'autoencoder_2' (type Autoencoder):\n      • x=tf.Tensor(shape=(None, 80, 3), dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "history=autoencoder.fit(X_train, X_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2lpwS6sPv3x"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# class Autoencoder(Model):\n",
        "#     def __init__(self, latent_dim, shape):\n",
        "#         super(Autoencoder, self).__init__()  # Call super().__init__()\n",
        "#         self.latent_dim = latent_dim\n",
        "#         self.shape = shape\n",
        "#         self.encoder = tf.keras.Sequential([\n",
        "#             layers.InputLayer(input_shape=shape),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2D(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2D(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.MaxPooling2D((2, 2)),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2))  # Adjusted to match the input shape\n",
        "#         ])\n",
        "#         self.decoder = tf.keras.Sequential([\n",
        "#             layers.Conv2DTranspose(32, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(64, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.UpSampling2D((2, 2)),  # Adjusted to match the downsampling factor\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Conv2DTranspose(128, (2, 2), activation='relu', padding='same'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.Dropout(0.1),\n",
        "#             layers.Conv2DTranspose(shape[-1], (3, 3), activation='sigmoid', padding='same')\n",
        "#         ])\n",
        "#         self.build((None,) + shape)  # Explicitly build the model\n",
        "\n",
        "#     def call(self, x):\n",
        "#         encoded = tf.cast(x, tf.float32)  # Cast input data to float32\n",
        "#         encoded = self.encoder(encoded)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return decoded\n",
        "\n",
        "# # Define shape and latent dimension\n",
        "# shape = (80, 80, 3)\n",
        "# latent_dim = 4\n",
        "\n",
        "# # Instantiate autoencoder\n",
        "# autoencoder = Autoencoder(latent_dim, shape)\n",
        "\n",
        "# # Compile autoencoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCCKXoA4QCCK"
      },
      "outputs": [],
      "source": [
        "# autoencoder.compile(loss='mse',\n",
        "#                     optimizer=Adam(learning_rate=0.1),\n",
        "#                     metrics=['accuracy'])\n",
        "\n",
        "# # Train autoencoder\n",
        "# history = autoencoder.fit(X_train, X_train,\n",
        "#                           epochs=5,\n",
        "#                           shuffle=True,\n",
        "#                           validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential\n",
        "\n",
        "# Define the model architecture using Sequential API\n",
        "model = Sequential([\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(80, 80, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.1),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.1),\n",
        "\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.1),\n",
        "\n",
        "    layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.1),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUuHWM8qY8a4",
        "outputId": "3374177a-eea8-4f5a-906a-d3f36434c329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 80, 80, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 80, 80, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 80, 80, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 80, 80, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 40, 40, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 40, 40, 64)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 40, 40, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 20, 20, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 20, 20, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 20, 20, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 20, 20, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 20, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 20, 20, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 10, 10, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 10, 10, 16)        64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 10, 10, 16)        2320      \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 10, 10, 16)        64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 10, 10, 8)         1160      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 5, 5, 8)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 5, 5, 8)           32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 5, 5, 8)           584       \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 5, 5, 8)           32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 5, 5, 8)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              205824    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 286004 (1.09 MB)\n",
            "Trainable params: 285524 (1.09 MB)\n",
            "Non-trainable params: 480 (1.88 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = autoencoder.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_pred_classes[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYgz-tENceSh",
        "outputId": "6f2beb99-8f6a-4633-bf92-2ab8b25cb798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 19, 19],\n",
              "       [19, 19, 19],\n",
              "       [20, 20,  0],\n",
              "       [22, 23,  0],\n",
              "       [21, 23,  0],\n",
              "       [21, 23,  0],\n",
              "       [15, 51,  0],\n",
              "       [14, 14,  0],\n",
              "       [12, 12, 74],\n",
              "       [ 7,  7, 75],\n",
              "       [ 6,  7, 40],\n",
              "       [ 5,  6, 35],\n",
              "       [ 5, 28, 30],\n",
              "       [ 5, 25, 26],\n",
              "       [ 6, 22, 22],\n",
              "       [18, 19, 20],\n",
              "       [14, 15, 15],\n",
              "       [12, 13, 14],\n",
              "       [10, 11, 12],\n",
              "       [ 8,  9, 10],\n",
              "       [ 6,  6,  7],\n",
              "       [ 4,  5,  5],\n",
              "       [ 4,  4,  4],\n",
              "       [ 4,  4,  4],\n",
              "       [ 4,  4,  5],\n",
              "       [ 4,  4,  4],\n",
              "       [ 4,  4,  4],\n",
              "       [ 3,  4,  4],\n",
              "       [ 3,  3,  4],\n",
              "       [ 3,  4,  4],\n",
              "       [ 3,  4,  4],\n",
              "       [ 4,  4,  4],\n",
              "       [ 3,  4,  4],\n",
              "       [ 3,  3,  4],\n",
              "       [ 2,  3,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  2,  3],\n",
              "       [ 2,  3,  3],\n",
              "       [ 2,  3,  3],\n",
              "       [ 2,  3,  3],\n",
              "       [ 2,  3,  3],\n",
              "       [ 2,  3,  3],\n",
              "       [ 2,  3,  3],\n",
              "       [ 3,  3,  4],\n",
              "       [ 3,  4,  4],\n",
              "       [ 4,  4,  4],\n",
              "       [ 4,  5,  5],\n",
              "       [ 6,  6,  6],\n",
              "       [ 6,  7,  7],\n",
              "       [ 7,  8,  8],\n",
              "       [ 8,  8,  8],\n",
              "       [ 8,  8,  8],\n",
              "       [ 8,  8,  8],\n",
              "       [ 8,  8,  8],\n",
              "       [ 8,  9,  9],\n",
              "       [ 9,  9, 10],\n",
              "       [ 9, 10, 10],\n",
              "       [10, 10, 10],\n",
              "       [11, 11, 12],\n",
              "       [13, 13, 14],\n",
              "       [16, 16, 17],\n",
              "       [18, 18, 19],\n",
              "       [19, 20, 20],\n",
              "       [ 3, 27, 29],\n",
              "       [30, 32, 34],\n",
              "       [61, 70, 70],\n",
              "       [61, 68, 68],\n",
              "       [69, 69, 69],\n",
              "       [ 0,  0,  0],\n",
              "       [10,  0,  0],\n",
              "       [10,  0,  0],\n",
              "       [11, 43,  0],\n",
              "       [19, 63, 63],\n",
              "       [12, 16, 59],\n",
              "       [12, 14, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "h0z0ypFRQGOy",
        "outputId": "c4c61d49-e166-48f2-ae67-24884256c3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 36ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-62e9f49b1e44>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Get the confusion matrix\n",
        "conf_matrix = confusion_matrix(Y_test, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute other evaluation metrics\n",
        "accuracy = accuracy_score(Y_test, y_pred_classes)\n",
        "precision = precision_score(Y_test, y_pred_classes, average='macro')\n",
        "recall = recall_score(Y_test, y_pred_classes, average='macro')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXIMlYtUxQMc",
        "outputId": "c6adf33a-45a8-43a8-bba7-bf5586618aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 38ms/step - loss: 4125.2202 - accuracy: 0.9992\n",
            "Test loss: 4125.22021484375\n",
            "Test accuracy: 0.9991746544837952\n"
          ]
        }
      ],
      "source": [
        "scores = autoencoder.evaluate(X_test, X_test)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arnyJnCcSeSJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADN2QSMDVR9j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "eb5db7ea-4c75-40c7-b8d0-8911e7a7ffcd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Exception encountered when calling layer 'conv2d_1' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[861,128,81,81] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D] name: \n\nCall arguments received by layer 'conv2d_1' (type Conv2D):\n  • inputs=tf.Tensor(shape=(861, 80, 80, 128), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-12b1ba32cd34>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split the encoded test data into training and testing sets for each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_encoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_encoded_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'conv2d_1' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[861,128,81,81] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D] name: \n\nCall arguments received by layer 'conv2d_1' (type Conv2D):\n  • inputs=tf.Tensor(shape=(861, 80, 80, 128), dtype=float32)"
          ]
        }
      ],
      "source": [
        "# Split the encoded test data into training and testing sets for each model\n",
        "encoded_test_data = autoencoder.encoder(X_test)\n",
        "X_encoded_train, X_encoded_test, y_encoded_train, y_encoded_test = train_test_split(encoded_test_data, y_test, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KlKNXdUSftQ"
      },
      "outputs": [],
      "source": [
        "# Encode the data using the trained autoencoder (remove this part)\n",
        "# X_encoded_train = autoencoder.encoder.predict(X_train)\n",
        "# X_encoded_test = autoencoder.encoder.predict(X_test)\n",
        "\n",
        "# Now you can use the original data for classification\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, Y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "cm_knn = confusion_matrix(Y_test, y_pred_knn)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, Y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "cm_rf = confusion_matrix(Y_test, y_pred_rf)\n",
        "\n",
        "# SVM\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(X_train, Y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "cm_svm = confusion_matrix(Y_test, y_pred_svm)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, Y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "cm_lr = confusion_matrix(Y_test, y_pred_lr)\n",
        "\n",
        "# SGD\n",
        "sgd = SGDClassifier(random_state=42)\n",
        "sgd.fit(X_train, Y_train)\n",
        "y_pred_sgd = sgd.predict(X_test)\n",
        "cm_sgd = confusion_matrix(Y_test, y_pred_sgd)\n",
        "\n",
        "# MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "mlp.fit(X_train, Y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "cm_mlp = confusion_matrix(Y_test, y_pred_mlp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heAA3I9PxitJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
        "\n",
        "# Get reconstructed outputs for X_train and X_test\n",
        "reconstructed_train = autoencoder.predict(X_train)\n",
        "reconstructed_test = autoencoder.predict(X_test)\n",
        "\n",
        "# Assuming y_train and y_test contain the true labels for X_train and X_test respectively\n",
        "# Compute confusion matrix, F1 score, and recall for train and test sets\n",
        "y_train_pred = np.argmax(reconstructed_train, axis=3).flatten()\n",
        "y_train_true = np.argmax(X_train, axis=3).flatten()\n",
        "train_conf_matrix = confusion_matrix(y_train_true, y_train_pred)\n",
        "train_f1_score = f1_score(y_train_true, y_train_pred, average='weighted')\n",
        "train_recall = recall_score(y_train_true, y_train_pred, average='weighted')\n",
        "\n",
        "y_test_pred = np.argmax(reconstructed_test, axis=3).flatten()\n",
        "y_test_true = np.argmax(X_test, axis=3).flatten()\n",
        "test_conf_matrix = confusion_matrix(y_test_true, y_test_pred)\n",
        "test_f1_score = f1_score(y_test_true, y_test_pred, average='weighted')\n",
        "test_recall = recall_score(y_test_true, y_test_pred, average='weighted')\n",
        "\n",
        "print(\"Train Confusion Matrix:\")\n",
        "print(train_conf_matrix)\n",
        "print(\"Train F1 Score:\", train_f1_score)\n",
        "print(\"Train Recall:\", train_recall)\n",
        "\n",
        "print(\"\\nTest Confusion Matrix:\")\n",
        "print(test_conf_matrix)\n",
        "print(\"Test F1 Score:\", test_f1_score)\n",
        "print(\"Test Recall:\", test_recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_Spyqdxxma6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lr_range_test(X_train, X_test, shape, latent_dim, start_lr, end_lr, batch_size, epochs):\n",
        "    autoencoder = Autoencoder(latent_dim, shape)\n",
        "\n",
        "    # Define a learning rate scheduler callback\n",
        "    def lr_scheduler(epoch, lr):\n",
        "        return start_lr * (end_lr / start_lr) ** (epoch / epochs)\n",
        "\n",
        "    # Compile the model with an initial learning rate\n",
        "    autoencoder.compile(loss='mse', optimizer=Adam(learning_rate=start_lr), metrics=['accuracy'])\n",
        "\n",
        "    # Define the LearningRateScheduler callback\n",
        "    lr_callback = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "    # Train the model with LR range test\n",
        "    history = autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, shuffle=True,\n",
        "                               validation_data=(X_test, X_test), callbacks=[lr_callback], verbose=0)\n",
        "\n",
        "    return history.history['loss'], history.history['accuracy'], autoencoder\n",
        "\n",
        "# Define LR range test parameters\n",
        "start_lr = 1e-7\n",
        "end_lr = 10\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Perform LR range test\n",
        "losses, accuracies, autoencoder = lr_range_test(X_train, X_test, shape, latent_dim, start_lr, end_lr, batch_size, epochs)\n",
        "\n",
        "# Plot the learning rate vs. loss curve\n",
        "learning_rates = start_lr * (end_lr / start_lr) ** (np.arange(epochs) / epochs)\n",
        "plt.plot(learning_rates, losses)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Rate vs. Loss')\n",
        "plt.show()\n",
        "\n",
        "# Plot the learning rate vs. accuracy curve\n",
        "plt.plot(learning_rates, accuracies)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Rate vs. Accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79_izbVQUsvN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}